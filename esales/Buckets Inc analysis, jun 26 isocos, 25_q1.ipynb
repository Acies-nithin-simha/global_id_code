{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3b02fd",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format','{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83086d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonesales = pd.read_parquet('../Data/nonesales_pivoted_2025_cleaned_v2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc55efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales = pd.read_parquet('../Data/esales_pivoted_2025_cleaned_v2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_list(tp):\n",
    "    yy, mon_str, k_str = tp.split('_')\n",
    "    k = int(k_str)\n",
    "    base_year = 2000 + int(yy)\n",
    "    start_date = datetime.strptime(f'{mon_str}_{base_year - 1}', '%b_%Y') + relativedelta(months=1)\n",
    "    return [(start_date + relativedelta(months=i)).strftime('%Y-%m') for i in range(k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0110c3",
   "metadata": {},
   "source": [
    "# Time Level 12 months apr-24 to mar-25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1ccab",
   "metadata": {},
   "source": [
    "## Time Level Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = '24_jun_12'\n",
    "tp2 = '25_jun_12'\n",
    "\n",
    "\n",
    "tp1_cols = get_month_list(tp1)\n",
    "tp2_cols = get_month_list(tp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91860032",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f67226",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales_df = esales[['global_id','flag_gl_id'] + tp1_cols + tp2_cols]\n",
    "nonesales_df = nonesales[['global_id','flag_gl_id'] + tp1_cols + tp2_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392b2ca",
   "metadata": {},
   "source": [
    "## Pre Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab930f7a",
   "metadata": {},
   "source": [
    "### Analysis Pre steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(df, tp1, tp2, tp1_cols, tp2_cols):\n",
    "    df = df.copy()\n",
    "    tp1_array = df[tp1_cols].to_numpy()\n",
    "    tp2_array = df[tp2_cols].to_numpy()\n",
    "\n",
    "    tp1_total = tp1_array.sum(axis=1)\n",
    "    tp2_total = tp2_array.sum(axis=1)\n",
    "\n",
    "    tp1_active = (tp1_array != 0).sum(axis=1)\n",
    "    tp2_active = (tp2_array != 0).sum(axis=1)\n",
    "\n",
    "    tp1_avg = np.divide(tp1_total, tp1_active, out=np.zeros_like(tp1_total, dtype=float), where=tp1_active != 0)\n",
    "    tp2_avg = np.divide(tp2_total, tp2_active, out=np.zeros_like(tp2_total, dtype=float), where=tp2_active != 0)\n",
    "\n",
    "    def masked_std(arr):\n",
    "        masked = np.ma.masked_where(arr == 0, arr)\n",
    "        return masked.std(axis=1, ddof=0)\n",
    "\n",
    "    tp1_std = masked_std(tp1_array)\n",
    "    tp2_std = masked_std(tp2_array)\n",
    "\n",
    "    df[f'{tp1}_Total'] = tp1_total\n",
    "    df[f'{tp2}_Total'] = tp2_total\n",
    "    df[f'months_active_{tp1}'] = tp1_active\n",
    "    df[f'months_active_{tp2}'] = tp2_active\n",
    "    df[f'avg_act_monthly_{tp1}'] = tp1_avg\n",
    "    df[f'avg_act_monthly_{tp2}'] = tp2_avg\n",
    "    df[f'std_dev_{tp1}'] = tp1_std\n",
    "    df[f'std_dev_{tp2}'] = tp2_std\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8fa52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales_df = calc_metrics(esales_df,tp1, tp2,tp1_cols,tp2_cols)\n",
    "nonesales_df = calc_metrics(nonesales_df,tp1, tp2,tp1_cols,tp2_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53592703",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales_df['25_jun_12_Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ff683",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(nonesales_df, esales_df, on='global_id', how='outer', suffixes=('_nonesales', '_esales'))\n",
    "merged_df['flag_gl_id'] = merged_df['flag_gl_id_esales'].combine_first(merged_df['flag_gl_id_nonesales'])\n",
    "merged_df.drop(columns=['flag_gl_id_esales','flag_gl_id_nonesales'],inplace=True)\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "usag_df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ad9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df['25_jun_12_Total_esales'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f0cb2",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763cbdf0",
   "metadata": {},
   "source": [
    "### Distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682736b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_segment(df, k, stype, atype, tp1, tp2):\n",
    "    avg_tp1 = df[f'avg_{atype}_monthly_{tp1}_{stype}']\n",
    "    avg_tp2 = df[f'avg_{atype}_monthly_{tp2}_{stype}']\n",
    "    std_tp1 = df[f'std_dev_{tp1}_{stype}']\n",
    "    months_tp1 = df[f'months_active_{tp1}_{stype}']\n",
    "\n",
    "    conditions = [\n",
    "        (avg_tp1 == 0) & (avg_tp2 == 0),\n",
    "        avg_tp1 == 0,\n",
    "        avg_tp2 == 0,\n",
    "        months_tp1 <= 1,\n",
    "        avg_tp2 < avg_tp1 - k * std_tp1,\n",
    "        avg_tp2 > avg_tp1 + k * std_tp1\n",
    "    ]\n",
    "\n",
    "    choices = [\n",
    "        \"Not in Channel\",\n",
    "        \"New\",\n",
    "        \"Declining\",\n",
    "        \"Unallocated\",\n",
    "        \"Declining\",\n",
    "        \"Growing\"\n",
    "    ]\n",
    "\n",
    "    print(avg_tp1.sum(), avg_tp2.sum(), std_tp1.sum(), months_tp1.sum())\n",
    "    return np.select(conditions, choices, default=\"Stable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e53479",
   "metadata": {},
   "outputs": [],
   "source": [
    "stypes = ['esales', 'nonesales']\n",
    "atypes = ['act']\n",
    "ks = [1]\n",
    "\n",
    "for stype in stypes:\n",
    "    for atype in atypes:\n",
    "        for k in ks:\n",
    "            usag_df[f'{tp1}_{tp2}_{atype}_mon_{stype}_sd_{str(k)}_segment'] = assign_segment(usag_df,k, stype, atype, tp1, tp2)\n",
    "            print(f'{tp1}_{tp2}_{atype}_mon_{stype}_sd_{str(k)}_segment done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_segments = usag_df[['global_id',f'{tp1}_{tp2}_act_mon_esales_sd_1_segment',f'{tp1}_{tp2}_act_mon_nonesales_sd_1_segment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e798c",
   "metadata": {},
   "source": [
    "### YoY assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c967e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_yoy(df, stype, tp1, tp2):\n",
    "    total_tp1 = df[f'{tp1}_Total_{stype}']\n",
    "    total_tp2 = df[f'{tp2}_Total_{stype}']\n",
    "    \n",
    "    cond1 = (total_tp1 <= 2) & (total_tp2 <= 2)\n",
    "    cond2 = (total_tp1 <= 2) & (total_tp2 > 2)\n",
    "    \n",
    "    conditions = [cond1, cond2]\n",
    "    choices = [0, 1]\n",
    "\n",
    "    yoy = np.select(conditions, choices, default=(total_tp2 / total_tp1) - 1)\n",
    "    \n",
    "    return yoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df[f'{tp1}_{tp2}_esales_yoy'] = compute_yoy(usag_df,'esales', tp1, tp2)\n",
    "usag_df[f'{tp1}_{tp2}_nonesales_yoy'] = compute_yoy(usag_df,'nonesales', tp1, tp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc304a",
   "metadata": {},
   "source": [
    "## New Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_bins = [-np.inf,0,0.001,500,1000,2500, 5000, 10000, 25000, np.inf]\n",
    "buckets = ['<0','0','0-500','500-1000','1000-2500','2500-5000', '5000-10000', '10000-25000', '25000+']\n",
    "\n",
    "usag_df[f'{tp1}_bucket'] = pd.cut(usag_df[f'{tp1}_Total_esales'], bins=bucket_bins, labels=buckets, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f03be",
   "metadata": {},
   "source": [
    "## Inc Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a01a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stypes = ['esales', 'nonesales']\n",
    "atypes = ['act']\n",
    "ks = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df[f'{tp1}_bucket'] = usag_df[f'{tp1}_bucket'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales_buckets = usag_df.groupby([f'{tp1}_bucket',])[[f'{tp1}_Total_esales',f'{tp2}_Total_esales']].sum().reset_index()\n",
    "esales_buckets['comp_bucket_YoY'] = (esales_buckets[f'{tp2}_Total_esales']/esales_buckets[f'{tp1}_Total_esales'])-1\n",
    "esales_buckets = esales_buckets[[f'{tp1}_bucket','comp_bucket_YoY']]\n",
    "usag_df = usag_df.merge(esales_buckets,how='left',on=[f'{tp1}_bucket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_buckets = usag_df.groupby([f'{tp1}_bucket'])['global_id'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_buckets = usag_df.groupby([f'{tp1}_bucket'])[[f'{tp1}_Total_esales',f'{tp2}_Total_esales',f'{tp1}_Total_nonesales',f'{tp2}_Total_nonesales']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d67074",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_buckets = rev_buckets.merge(cust_buckets, on=[f'{tp1}_bucket'],how='inner')\n",
    "rev_buckets['esales_yoy'] = (rev_buckets[f'{tp2}_Total_esales']/rev_buckets[f'{tp1}_Total_esales'])-1\n",
    "rev_buckets['nonesales_yoy'] = (rev_buckets[f'{tp2}_Total_nonesales']/rev_buckets[f'{tp1}_Total_nonesales'])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3075b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b16d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_buckets.to_excel('revenue buckets summary.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24941768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esales_buckets.to_excel('esales_buckets.xlsx')\n",
    "esales_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a52f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales_buckets.to_excel('esales_buckets_segment.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e615a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_increment(df, seg_col, tp1, tp2):\n",
    "    yoy_col = f'{tp1}_{tp2}_esales_yoy'\n",
    "    bucket_col = f'{tp1}_bucket'\n",
    "    comp_yoy_col = 'comp_bucket_YoY'\n",
    "\n",
    "    conditions = [\n",
    "        df[seg_col] == 'Not in Channel',\n",
    "        df[bucket_col].isin(['<0', '0'])\n",
    "    ]\n",
    "    \n",
    "    choices = [\n",
    "        0.0,\n",
    "        df[yoy_col]\n",
    "    ]\n",
    "    \n",
    "    inc_pct = np.select(conditions, choices, default=df[yoy_col] - df[comp_yoy_col])\n",
    "    return inc_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_col = f'{tp1}_{tp2}_act_mon_esales_sd_1_segment'\n",
    "cust_count = usag_df[(usag_df[seg_col]=='Not in Channel')].shape[0]\n",
    "cust_count = len(usag_df) - cust_count\n",
    "cust_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507034c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df[f'{tp1}_{tp2}_esales_incremental_pct'] = compute_increment(usag_df,seg_col, tp1, tp2)\n",
    "usag_df[f'{tp1}_{tp2}_esales_incremental_abs'] = usag_df[f'{tp1}_{tp2}_esales_incremental_pct'] * usag_df[f'{tp1}_Total_esales']\n",
    "print(usag_df[f'{tp1}_{tp2}_esales_incremental_abs'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df.groupby(f'{tp1}_{tp2}_act_mon_esales_sd_1_segment')['global_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589e7d3",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df.to_parquet(f'Outputs/usag_{tp1}_{tp2}_bucket_isocos_peinc_updated.parquet',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03630af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usag_df[usag_df['24_jun_12_bucket']=='25000+'][['24_jun_12_bucket','global_id','STO__OWNERSHIP_TYPE_CODE']+[item + '_esales' for item in tp1_cols]+[item + '_esales' for item in tp1_cols]].to_excel('25000+ customers.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc39bbc",
   "metadata": {},
   "source": [
    "## Post Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4841d48",
   "metadata": {},
   "source": [
    "### Crosstab creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459dc3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segments = ['Unallocated', 'New', 'Growing', 'Stable', 'Declining', 'Not in Channel']\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4859412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab_func(usag_df,atype,k,tp1,tp2):\n",
    "    metric_rows = ['# of Customers', 'eSales_Inc', f'eSales {tp1}', f'eSales {tp2}']\n",
    "    metric_cols = ['.','..', f'non-eSales {tp1}', f'non-eSales {tp2}']\n",
    "\n",
    "\n",
    "    row_index = pd.MultiIndex.from_product([segments, metric_rows])\n",
    "    col_index = pd.MultiIndex.from_product([segments, metric_cols])\n",
    "\n",
    "\n",
    "    cross_tab = pd.DataFrame(index=row_index, columns=col_index)\n",
    "\n",
    "\n",
    "    total_nonesales_tp1 = usag_df[f'{tp1}_Total_nonesales'].sum()\n",
    "    total_nonesales_tp2 = usag_df[f'{tp2}_Total_nonesales'].sum()\n",
    "    total_esales_tp1 = usag_df[f'{tp1}_Total_esales'].sum()\n",
    "    total_esales_tp2 = usag_df[f'{tp2}_Total_esales'].sum()\n",
    "\n",
    "    for e_seg in segments:\n",
    "        for n_seg in segments:\n",
    "            subset = usag_df[\n",
    "                (usag_df[f'{tp1}_{tp2}_{atype}_mon_esales_sd_{str(k)}_segment'] == e_seg) &\n",
    "                (usag_df[f'{tp1}_{tp2}_{atype}_mon_nonesales_sd_{str(k)}_segment'] == n_seg)\n",
    "            ]\n",
    "\n",
    "            num_customers = subset.shape[0]\n",
    "            esales_tp1 = subset[f'{tp1}_Total_esales'].sum()\n",
    "            esales_tp2 = subset[f'{tp2}_Total_esales'].sum()\n",
    "            nonesales_tp1 = subset[f'{tp1}_Total_nonesales'].sum()\n",
    "            nonesales_tp2 = subset[f'{tp2}_Total_nonesales'].sum()\n",
    "\n",
    "            esales_inc = subset[f'{tp1}_{tp2}_esales_incremental_abs'].sum()\n",
    "\n",
    "            cross_tab.loc[(e_seg, '# of Customers'), (n_seg, '.')] = num_customers\n",
    "            cross_tab.loc[(e_seg, '# of Customers'), (n_seg, f'non-eSales {tp1}')] = f\"{nonesales_tp1:.0f}\"\n",
    "            cross_tab.loc[(e_seg, '# of Customers'), (n_seg, f'non-eSales {tp2}')] = f\"{nonesales_tp2:.0f}\"\n",
    "            cross_tab.loc[(e_seg, 'eSales_Inc'), (n_seg, f'non-eSales {tp1}')] = f\"{(nonesales_tp1/total_nonesales_tp1):.2%}\"\n",
    "            cross_tab.loc[(e_seg, 'eSales_Inc'), (n_seg, f'non-eSales {tp2}')] = f\"{(nonesales_tp2/total_nonesales_tp2):.2%}\"\n",
    "\n",
    "            cross_tab.loc[(e_seg, 'eSales_Inc'), (n_seg, '.')] = f\"{esales_inc:.0f}\"\n",
    "\n",
    "            cross_tab.loc[(e_seg, f'eSales {tp1}'), (n_seg, '.')] = f\"{esales_tp1:.0f}\"\n",
    "            cross_tab.loc[(e_seg, f'eSales {tp2}'), (n_seg, '.')] = f\"{esales_tp2:.0f}\"\n",
    "            cross_tab.loc[(e_seg, f'eSales {tp1}'), (n_seg, '..')] = f\"{(esales_tp1/total_esales_tp1):.2%}\"\n",
    "            cross_tab.loc[(e_seg, f'eSales {tp2}'), (n_seg, '..')] = f\"{(esales_tp2/total_esales_tp2):.2%}\"\n",
    "\n",
    "\n",
    "    return cross_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_dict = {}\n",
    "for atype in atypes:\n",
    "    for k in ks:\n",
    "        sheet_name = f\"cross_tab_{tp1}_{tp2}_{atype}_mon_sd_{str(k)}\"\n",
    "        sheet_dict[sheet_name] = crosstab_func(usag_df,atype, k,tp1, tp2)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5213ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_dict[f'cross_tab_{tp1}_{tp2}_act_mon_sd_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f\"crosstab_output_bucket_pe_{tp1}_{tp2}.xlsx\") as writer:\n",
    "    for sheet_name, df in sheet_dict.items():\n",
    "        df.to_excel(writer,sheet_name = sheet_name[:31])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985af7a",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50841e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e14f2229",
   "metadata": {},
   "source": [
    "# Time Level 9 months apr-24 to dec-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ffa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df_proxy = usag_segments#pd.read_csv(f'usag_{tp1}_{tp2}_bucket_peinc_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326cb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_proxy_1 = tp1\n",
    "tp_proxy_2 = tp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usag_df_proxy.to_csv(f'usag_{tp_proxy_1}_{tp_proxy_2}_peinc_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc4750f",
   "metadata": {},
   "source": [
    "## Time Level Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = '24_jun_9'\n",
    "tp2 = '25_jun_9'\n",
    "\n",
    "\n",
    "tp1_cols = get_month_list(tp1)\n",
    "tp2_cols = get_month_list(tp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768fbdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales_df = esales_df[['global_id','flag_gl_id'] + tp1_cols + tp2_cols]\n",
    "nonesales_df = nonesales_df[['global_id','flag_gl_id'] + tp1_cols + tp2_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36cf93",
   "metadata": {},
   "source": [
    "## Pre Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b71acf",
   "metadata": {},
   "source": [
    "### Analysis Pre steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(df, tp1, tp2, tp1_cols, tp2_cols):\n",
    "    df = df.copy()\n",
    "    tp1_array = df[tp1_cols].to_numpy()\n",
    "    tp2_array = df[tp2_cols].to_numpy()\n",
    "\n",
    "    tp1_total = tp1_array.sum(axis=1)\n",
    "    tp2_total = tp2_array.sum(axis=1)\n",
    "\n",
    "    tp1_active = (tp1_array != 0).sum(axis=1)\n",
    "    tp2_active = (tp2_array != 0).sum(axis=1)\n",
    "\n",
    "    tp1_avg = np.divide(tp1_total, tp1_active, out=np.zeros_like(tp1_total, dtype=float), where=tp1_active != 0)\n",
    "    tp2_avg = np.divide(tp2_total, tp2_active, out=np.zeros_like(tp2_total, dtype=float), where=tp2_active != 0)\n",
    "\n",
    "    def masked_std(arr):\n",
    "        masked = np.ma.masked_where(arr == 0, arr)\n",
    "        return masked.std(axis=1, ddof=0)\n",
    "\n",
    "    tp1_std = masked_std(tp1_array)\n",
    "    tp2_std = masked_std(tp2_array)\n",
    "\n",
    "    df[f'{tp1}_Total'] = tp1_total\n",
    "    df[f'{tp2}_Total'] = tp2_total\n",
    "    df[f'months_active_{tp1}'] = tp1_active\n",
    "    df[f'months_active_{tp2}'] = tp2_active\n",
    "    df[f'avg_act_monthly_{tp1}'] = tp1_avg\n",
    "    df[f'avg_act_monthly_{tp2}'] = tp2_avg\n",
    "    df[f'std_dev_{tp1}'] = tp1_std\n",
    "    df[f'std_dev_{tp2}'] = tp2_std\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2065dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales_df = calc_metrics(esales_df,tp1, tp2,tp1_cols,tp2_cols)\n",
    "nonesales_df = calc_metrics(nonesales_df,tp1, tp2,tp1_cols,tp2_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc225b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(nonesales_df, esales_df, on='global_id', how='outer', suffixes=('_nonesales', '_esales'))\n",
    "merged_df['flag_gl_id'] = merged_df['flag_gl_id_esales'].combine_first(merged_df['flag_gl_id_nonesales'])\n",
    "merged_df.drop(columns=['flag_gl_id_esales','flag_gl_id_nonesales'],inplace=True)\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "usag_df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37267d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usag_df.to_csv(f\"usag_{tp1}_{tp2}_unflagged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# months_2022, months_2023,months_2024,months_2025 = get_year_columns(nonesales_df)\n",
    "# months = months_2022 + months_2023 + months_2024 + months_2025\n",
    "\n",
    "\n",
    "\n",
    "# for month in months:\n",
    "#     usag_df[month] = usag_df[f'{month}_nonesales'] + usag_df[f'{month}_esales']\n",
    "\n",
    "# # usag_df = usag_df[['global_id'] + months]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94861fc9",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9eea31",
   "metadata": {},
   "source": [
    "### Distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment(row,k,stype,atype,tp1,tp2):\n",
    "    # print(f'avg_{atype}_monthly_2022_{stype}')\n",
    "    if row[f'avg_{atype}_monthly_{tp1}_{stype}'] == 0 and row[f'avg_{atype}_monthly_{tp2}_{stype}'] == 0:\n",
    "        return \"Not in Channel\"\n",
    "    elif row[f'avg_{atype}_monthly_{tp1}_{stype}'] == 0:\n",
    "        return \"New\"\n",
    "    elif row[f'avg_{atype}_monthly_{tp2}_{stype}'] == 0:\n",
    "        return \"Declining\"\n",
    "    elif row[f'months_active_{tp1}_{stype}'] <= 1:\n",
    "        return \"Unallocated\"\n",
    "    elif row[f'avg_{atype}_monthly_{tp2}_{stype}'] < row[f'avg_{atype}_monthly_{tp1}_{stype}'] - k * row[f'std_dev_{tp1}_{stype}']:\n",
    "        return \"Declining\"\n",
    "    elif row[f'avg_{atype}_monthly_{tp2}_{stype}'] > row[f'avg_{atype}_monthly_{tp1}_{stype}'] + k * row[f'std_dev_{tp1}_{stype}']:\n",
    "        return \"Growing\"\n",
    "    else:\n",
    "        return \"Stable\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97963a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stypes = ['esales', 'nonesales']\n",
    "atypes = ['act']\n",
    "ks = [1]\n",
    "\n",
    "# for stype in stypes:\n",
    "#     for atype in atypes:\n",
    "#         for k in ks:\n",
    "#             usag_df[f'{tp1}_{tp2}_{atype}_mon_{stype}_sd_{str(k)}_segment'] = usag_df.apply(lambda row: get_segment(row,k, stype,atype,tp1,tp2), axis=1 )\n",
    "#             print(f'{tp1}_{tp2}_{atype}_mon_{stype}_sd_{str(k)}_segment done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e7526",
   "metadata": {},
   "source": [
    "### YoY assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_yoy(df, stype, tp1, tp2):\n",
    "    total_tp1 = df[f'{tp1}_Total_{stype}']\n",
    "    total_tp2 = df[f'{tp2}_Total_{stype}']\n",
    "    \n",
    "    cond1 = (total_tp1 <= 2) & (total_tp2 <= 2)\n",
    "    cond2 = (total_tp1 <= 2) & (total_tp2 > 2)\n",
    "    \n",
    "    conditions = [cond1, cond2]\n",
    "    choices = [0, 1]\n",
    "\n",
    "    yoy = np.select(conditions, choices, default=(total_tp2 / total_tp1) - 1)\n",
    "    \n",
    "    return yoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7782fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df[f'{tp1}_{tp2}_esales_yoy'] = compute_yoy(usag_df,'esales', tp1, tp2)\n",
    "usag_df[f'{tp1}_{tp2}_nonesales_yoy'] = compute_yoy(usag_df,'nonesales', tp1, tp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usag_df.to_csv(f\"usag_{tp1}_{tp2}_flagged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c536a0e",
   "metadata": {},
   "source": [
    "## Inc Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ce970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usag_df = pd.read_csv(f\"usag_{tp1}_{tp2}_flagged.csv\")\n",
    "\n",
    "stypes = ['esales', 'nonesales']\n",
    "atypes = ['act']\n",
    "ks = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681945ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df_proxy_2 = usag_df_proxy[['global_id',f'{tp_proxy_1}_{tp_proxy_2}_act_mon_esales_sd_1_segment',f'{tp_proxy_1}_{tp_proxy_2}_act_mon_nonesales_sd_1_segment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0741313",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df=usag_df.merge(usag_df_proxy_2,how='inner',on='global_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e16656",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_bins = [-np.inf,0,0.001,500,1000,2500, 5000, 10000, 25000, np.inf]\n",
    "buckets = ['<0','0','0-500','500-1000','1000-2500','2500-5000', '5000-10000', '10000-25000', '25000+']\n",
    "\n",
    "usag_df[f'{tp1}_bucket'] = pd.cut(usag_df[f'{tp1}_Total_esales'], bins=bucket_bins, labels=buckets, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df[f'{tp1}_bucket'] = usag_df[f'{tp1}_bucket'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52351f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales_buckets = usag_df.groupby([f'{tp1}_bucket'])[[f'{tp1}_Total_esales',f'{tp2}_Total_esales']].sum().reset_index()\n",
    "esales_buckets['comp_bucket_YoY'] = (esales_buckets[f'{tp2}_Total_esales']/esales_buckets[f'{tp1}_Total_esales'])-1\n",
    "esales_buckets = esales_buckets[[f'{tp1}_bucket','comp_bucket_YoY']]\n",
    "usag_df = usag_df.merge(esales_buckets,how='left',on=[f'{tp1}_bucket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8633a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esales_buckets.to_excel('esales_buckets_9months.xlsx')\n",
    "esales_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "esales_yoy = ((usag_df[f'{tp2}_Total_esales'].sum())/(usag_df[f'{tp1}_Total_esales'].sum()))-1\n",
    "\n",
    "esales_ov_inc_abs = (usag_df[f'{tp2}_Total_esales'].sum())-(usag_df[f'{tp1}_Total_esales'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_increment(df, seg_col, tp1, tp2):\n",
    "    yoy_col = f'{tp1}_{tp2}_esales_yoy'\n",
    "    bucket_col = f'{tp1}_bucket'\n",
    "    comp_yoy_col = 'comp_bucket_YoY'\n",
    "\n",
    "    conditions = [\n",
    "        df[seg_col] == 'Not in Channel',\n",
    "        df[bucket_col].isin(['<0', '0'])\n",
    "    ]\n",
    "    \n",
    "    choices = [\n",
    "        0.0,\n",
    "        df[yoy_col]\n",
    "    ]\n",
    "    \n",
    "    inc_pct = np.select(conditions, choices, default=df[yoy_col] - df[comp_yoy_col])\n",
    "    return inc_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_col = f'{tp_proxy_1}_{tp_proxy_2}_act_mon_esales_sd_1_segment'\n",
    "cust_count = usag_df[(usag_df[seg_col]=='Not in Channel')].shape[0]\n",
    "cust_count = len(usag_df) - cust_count\n",
    "cust_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df[f'{tp1}_{tp2}_esales_incremental_pct'] = compute_increment(usag_df,seg_col, tp1, tp2)\n",
    "usag_df[f'{tp1}_{tp2}_esales_incremental_abs'] = usag_df[f'{tp1}_{tp2}_esales_incremental_pct'] * usag_df[f'{tp1}_Total_esales']\n",
    "print(usag_df[f'{tp1}_{tp2}_esales_incremental_abs'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f96bed",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36953b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usag_df['STO__OWNERSHIP_TYPE_CODE'] = usag_df['STO__OWNERSHIP_TYPE_CODE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "usag_df.to_parquet(f'Outputs/usag_{tp1}_{tp2}_bucket_isocos_peinc_updated.parquet',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25388572",
   "metadata": {},
   "source": [
    "## Post Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33afe699",
   "metadata": {},
   "source": [
    "### Crosstab creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cceaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segments = ['Unallocated', 'New', 'Growing', 'Stable', 'Declining', 'Not in Channel']\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab_func(usag_df,atype,k,tp1,tp2,tp_proxy_1,tp_proxy_2):\n",
    "    metric_rows = ['# of Customers', 'eSales_Inc', f'eSales {tp1}', f'eSales {tp2}']\n",
    "    metric_cols = ['.','..', f'non-eSales {tp1}', f'non-eSales {tp2}']\n",
    "\n",
    "\n",
    "    row_index = pd.MultiIndex.from_product([segments, metric_rows])\n",
    "    col_index = pd.MultiIndex.from_product([segments, metric_cols])\n",
    "\n",
    "\n",
    "    cross_tab = pd.DataFrame(index=row_index, columns=col_index)\n",
    "\n",
    "\n",
    "    total_nonesales_tp1 = usag_df[f'{tp1}_Total_nonesales'].sum()\n",
    "    total_nonesales_tp2 = usag_df[f'{tp2}_Total_nonesales'].sum()\n",
    "    total_esales_tp1 = usag_df[f'{tp1}_Total_esales'].sum()\n",
    "    total_esales_tp2 = usag_df[f'{tp2}_Total_esales'].sum()\n",
    "\n",
    "    for e_seg in segments:\n",
    "        for n_seg in segments:\n",
    "            subset = usag_df[\n",
    "                (usag_df[f'{tp_proxy_1}_{tp_proxy_2}_{atype}_mon_esales_sd_{str(k)}_segment'] == e_seg) &\n",
    "                (usag_df[f'{tp_proxy_1}_{tp_proxy_2}_{atype}_mon_nonesales_sd_{str(k)}_segment'] == n_seg)\n",
    "            ]\n",
    "\n",
    "            num_customers = subset.shape[0]\n",
    "            esales_tp1 = subset[f'{tp1}_Total_esales'].sum()\n",
    "            esales_tp2 = subset[f'{tp2}_Total_esales'].sum()\n",
    "            nonesales_tp1 = subset[f'{tp1}_Total_nonesales'].sum()\n",
    "            nonesales_tp2 = subset[f'{tp2}_Total_nonesales'].sum()\n",
    "\n",
    "            esales_inc = subset[f'{tp1}_{tp2}_esales_incremental_abs'].sum()\n",
    "\n",
    "            cross_tab.loc[(e_seg, '# of Customers'), (n_seg, '.')] = num_customers\n",
    "            cross_tab.loc[(e_seg, '# of Customers'), (n_seg, f'non-eSales {tp1}')] = f\"{nonesales_tp1:.0f}\"\n",
    "            cross_tab.loc[(e_seg, '# of Customers'), (n_seg, f'non-eSales {tp2}')] = f\"{nonesales_tp2:.0f}\"\n",
    "            cross_tab.loc[(e_seg, 'eSales_Inc'), (n_seg, f'non-eSales {tp1}')] = f\"{(nonesales_tp1/total_nonesales_tp1):.2%}\"\n",
    "            cross_tab.loc[(e_seg, 'eSales_Inc'), (n_seg, f'non-eSales {tp2}')] = f\"{(nonesales_tp2/total_nonesales_tp2):.2%}\"\n",
    "\n",
    "            cross_tab.loc[(e_seg, 'eSales_Inc'), (n_seg, '.')] = f\"{esales_inc:.0f}\"\n",
    "\n",
    "            cross_tab.loc[(e_seg, f'eSales {tp1}'), (n_seg, '.')] = f\"{esales_tp1:.0f}\"\n",
    "            cross_tab.loc[(e_seg, f'eSales {tp2}'), (n_seg, '.')] = f\"{esales_tp2:.0f}\"\n",
    "            cross_tab.loc[(e_seg, f'eSales {tp1}'), (n_seg, '..')] = f\"{(esales_tp1/total_esales_tp1):.2%}\"\n",
    "            cross_tab.loc[(e_seg, f'eSales {tp2}'), (n_seg, '..')] = f\"{(esales_tp2/total_esales_tp2):.2%}\"\n",
    "\n",
    "\n",
    "    return cross_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_dict = {}\n",
    "for atype in atypes:\n",
    "    for k in ks:\n",
    "        sheet_name = f\"cross_tab_{tp1}_{tp2}_{atype}_mon_sd_{str(k)}\"\n",
    "        sheet_dict[sheet_name] = crosstab_func(usag_df,atype, k,tp1, tp2,tp_proxy_1,tp_proxy_2)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8aac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_dict[f'cross_tab_{tp1}_{tp2}_act_mon_sd_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f\"crosstab_output_bucket_pe_{tp1}_{tp2}.xlsx\") as writer:\n",
    "    for sheet_name, df in sheet_dict.items():\n",
    "        df.to_excel(writer,sheet_name = sheet_name[:31])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6226af8",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b69c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
